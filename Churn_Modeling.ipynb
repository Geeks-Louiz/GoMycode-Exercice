{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Churn_Modeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjEHXCR48lcL/ao2S90YlH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geeks-Louiz/GoMycode-Exercice/blob/master/Churn_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqK5oaVSs_Bt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viadq4EYtN2l",
        "outputId": "545224fb-6e85-4b46-c03c-a5f0dc9985a2"
      },
      "source": [
        "data = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "print(data)\n",
        "y = data[\"Exited\"].value_counts()\n",
        "#print(y)\n",
        "geography = pd.get_dummies(data['Geography'], drop_first=True)\n",
        "gender = pd.get_dummies(data['Gender'], drop_first=True)\n",
        "#print(gender)\n",
        "data = pd.concat([data,geography,gender], axis=1)\n",
        "print(data)\n",
        "data.drop(['Surname', 'CustomerId','Geography','Gender'], axis=1, inplace=True)\n",
        "print (data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
            "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
            "1             2    15647311       Hill  ...               1       112542.58      0\n",
            "2             3    15619304       Onio  ...               0       113931.57      1\n",
            "3             4    15701354       Boni  ...               0        93826.63      0\n",
            "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
            "...         ...         ...        ...  ...             ...             ...    ...\n",
            "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
            "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
            "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
            "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
            "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
            "\n",
            "[10000 rows x 14 columns]\n",
            "      RowNumber  CustomerId    Surname  ...  Germany Spain Male\n",
            "0             1    15634602   Hargrave  ...        0     0    0\n",
            "1             2    15647311       Hill  ...        0     1    0\n",
            "2             3    15619304       Onio  ...        0     0    0\n",
            "3             4    15701354       Boni  ...        0     0    0\n",
            "4             5    15737888   Mitchell  ...        0     1    0\n",
            "...         ...         ...        ...  ...      ...   ...  ...\n",
            "9995       9996    15606229   Obijiaku  ...        0     0    1\n",
            "9996       9997    15569892  Johnstone  ...        0     0    1\n",
            "9997       9998    15584532        Liu  ...        0     0    0\n",
            "9998       9999    15682355  Sabbatini  ...        1     0    1\n",
            "9999      10000    15628319     Walker  ...        0     0    0\n",
            "\n",
            "[10000 rows x 17 columns]\n",
            "      RowNumber  CreditScore  Age  Tenure  ...  Exited  Germany  Spain  Male\n",
            "0             1          619   42       2  ...       1        0      0     0\n",
            "1             2          608   41       1  ...       0        0      1     0\n",
            "2             3          502   42       8  ...       1        0      0     0\n",
            "3             4          699   39       1  ...       0        0      0     0\n",
            "4             5          850   43       2  ...       0        0      1     0\n",
            "...         ...          ...  ...     ...  ...     ...      ...    ...   ...\n",
            "9995       9996          771   39       5  ...       0        0      0     1\n",
            "9996       9997          516   35      10  ...       0        0      0     1\n",
            "9997       9998          709   36       7  ...       1        0      0     0\n",
            "9998       9999          772   42       3  ...       1        1      0     1\n",
            "9999      10000          792   28       4  ...       0        0      0     0\n",
            "\n",
            "[10000 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVgP8c024IBu",
        "outputId": "bd78f578-b2e4-4cbf-f062-56e00607de5d"
      },
      "source": [
        "#Pas de valeurs manquantes\n",
        "print(data.isnull().sum())\n",
        "print(data.isnull().values.any())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RowNumber          0\n",
            "CreditScore        0\n",
            "Age                0\n",
            "Tenure             0\n",
            "Balance            0\n",
            "NumOfProducts      0\n",
            "HasCrCard          0\n",
            "IsActiveMember     0\n",
            "EstimatedSalary    0\n",
            "Exited             0\n",
            "Germany            0\n",
            "Spain              0\n",
            "Male               0\n",
            "dtype: int64\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gk7hnfb34yn",
        "outputId": "a2e247a8-e0cc-4636-86c4-5005c62caa23"
      },
      "source": [
        "dataX = data.drop('Exited', axis=1)\n",
        "dataY = data['Exited']\n",
        "print(dataX.shape)\n",
        "print(dataY.shape)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 12)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkzJCxfy4g4z",
        "outputId": "5b5ceeb5-a358-40f9-fc3c-74bff4659ac6"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(dataX,dataY,test_size=0.2,random_state=42)\n",
        "print('X_train size: {}, X_test size: {}'.format(X_train.shape, y_train.shape))\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train size: (8000, 12), X_test size: (8000,)\n",
            "[[ 1.4692775   0.35649971 -0.6557859  ... -0.57946723 -0.57638802\n",
            "   0.91324755]\n",
            " [-1.19499359 -0.20389777  0.29493847 ...  1.72572313 -0.57638802\n",
            "   0.91324755]\n",
            " [-1.15724427 -0.96147213 -1.41636539 ... -0.57946723  1.73494238\n",
            "   0.91324755]\n",
            " ...\n",
            " [ 0.13108128  0.86500853 -0.08535128 ... -0.57946723 -0.57638802\n",
            "  -1.09499335]\n",
            " [-1.43776677  0.15932282  0.3900109  ... -0.57946723 -0.57638802\n",
            "   0.91324755]\n",
            " [ 0.78217054  0.47065475  1.15059039 ...  1.72572313 -0.57638802\n",
            "   0.91324755]]\n",
            "[[ 0.42961263 -0.57749609 -0.6557859  ...  1.72572313 -0.57638802\n",
            "   0.91324755]\n",
            " [-0.11342351 -0.29729735  0.3900109  ... -0.57946723 -0.57638802\n",
            "   0.91324755]\n",
            " [-1.1361185  -0.52560743  0.48508334 ... -0.57946723  1.73494238\n",
            "  -1.09499335]\n",
            " ...\n",
            " [ 0.98407747  0.81311987  0.77030065 ... -0.57946723 -0.57638802\n",
            "  -1.09499335]\n",
            " [-1.35638061  0.41876609 -0.94100321 ... -0.57946723 -0.57638802\n",
            "   0.91324755]\n",
            " [ 0.66407403 -0.24540869  0.00972116 ...  1.72572313 -0.57638802\n",
            "   0.91324755]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGyNQVmC5_mX",
        "outputId": "e81406b7-e608-4b1f-a583-6028e0cab0d0"
      },
      "source": [
        "# Partie ANN\n",
        "\n",
        "model = Sequential()\n",
        "#1ére couche (first layer)\n",
        "model.add(Dense(units=6, activation='relu', input_dim=12))\n",
        "#2eme couche \n",
        "model.add(Dense(units=6, activation='relu'))\n",
        "#output layer\n",
        "model.add(Dense(units=1,activation='sigmoid')) # sigmoid car la sortie 0 et 1 \n",
        "# compile c'est létape de la backpropagation\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#batch_size --> c'est le nombre d'echantillon á traiter , epoch c'est le nombre de train\n",
        "model_history = classifier.fit(X_train, y_train, batch_size=10, validation_split=0.33, epochs=100)\n",
        "print(model_history)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 16s 3ms/step - loss: 0.5744 - accuracy: 0.7364 - val_loss: 0.4886 - val_accuracy: 0.7910\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4607 - accuracy: 0.8010 - val_loss: 0.4581 - val_accuracy: 0.7910\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.8061 - val_loss: 0.4452 - val_accuracy: 0.7910\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.7912 - val_loss: 0.4392 - val_accuracy: 0.7910\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.7931 - val_loss: 0.4335 - val_accuracy: 0.7910\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.7972 - val_loss: 0.4285 - val_accuracy: 0.7910\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4056 - accuracy: 0.8120 - val_loss: 0.4233 - val_accuracy: 0.8209\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8275 - val_loss: 0.4149 - val_accuracy: 0.8273\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4097 - accuracy: 0.8322 - val_loss: 0.4025 - val_accuracy: 0.8307\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3808 - accuracy: 0.8503 - val_loss: 0.3883 - val_accuracy: 0.8410\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8588 - val_loss: 0.3771 - val_accuracy: 0.8470\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8625 - val_loss: 0.3712 - val_accuracy: 0.8463\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8622 - val_loss: 0.3684 - val_accuracy: 0.8493\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8614 - val_loss: 0.3640 - val_accuracy: 0.8501\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8710 - val_loss: 0.3662 - val_accuracy: 0.8474\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8642 - val_loss: 0.3603 - val_accuracy: 0.8516\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8565 - val_loss: 0.3584 - val_accuracy: 0.8508\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8584 - val_loss: 0.3606 - val_accuracy: 0.8512\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8733 - val_loss: 0.3583 - val_accuracy: 0.8497\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8645 - val_loss: 0.3572 - val_accuracy: 0.8508\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8705 - val_loss: 0.3560 - val_accuracy: 0.8531\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8643 - val_loss: 0.3572 - val_accuracy: 0.8554\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8700 - val_loss: 0.3578 - val_accuracy: 0.8512\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8691 - val_loss: 0.3568 - val_accuracy: 0.8497\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8757 - val_loss: 0.3560 - val_accuracy: 0.8516\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.8711 - val_loss: 0.3540 - val_accuracy: 0.8527\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8676 - val_loss: 0.3553 - val_accuracy: 0.8523\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8656 - val_loss: 0.3554 - val_accuracy: 0.8523\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8631 - val_loss: 0.3561 - val_accuracy: 0.8557\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8711 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8724 - val_loss: 0.3579 - val_accuracy: 0.8519\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8657 - val_loss: 0.3554 - val_accuracy: 0.8542\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8708 - val_loss: 0.3553 - val_accuracy: 0.8527\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8727 - val_loss: 0.3569 - val_accuracy: 0.8542\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3116 - accuracy: 0.8692 - val_loss: 0.3568 - val_accuracy: 0.8550\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8685 - val_loss: 0.3554 - val_accuracy: 0.8542\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8689 - val_loss: 0.3558 - val_accuracy: 0.8527\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8686 - val_loss: 0.3554 - val_accuracy: 0.8550\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8642 - val_loss: 0.3554 - val_accuracy: 0.8531\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8686 - val_loss: 0.3557 - val_accuracy: 0.8542\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8676 - val_loss: 0.3554 - val_accuracy: 0.8542\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8566 - val_loss: 0.3572 - val_accuracy: 0.8535\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8661 - val_loss: 0.3562 - val_accuracy: 0.8546\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8765 - val_loss: 0.3570 - val_accuracy: 0.8512\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8662 - val_loss: 0.3557 - val_accuracy: 0.8497\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8636 - val_loss: 0.3570 - val_accuracy: 0.8523\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8674 - val_loss: 0.3561 - val_accuracy: 0.8504\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8652 - val_loss: 0.3561 - val_accuracy: 0.8516\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8711 - val_loss: 0.3570 - val_accuracy: 0.8519\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8769 - val_loss: 0.3566 - val_accuracy: 0.8516\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8681 - val_loss: 0.3584 - val_accuracy: 0.8493\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8589 - val_loss: 0.3589 - val_accuracy: 0.8516\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8659 - val_loss: 0.3555 - val_accuracy: 0.8542\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8657 - val_loss: 0.3557 - val_accuracy: 0.8527\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8605 - val_loss: 0.3580 - val_accuracy: 0.8523\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8677 - val_loss: 0.3576 - val_accuracy: 0.8504\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8711 - val_loss: 0.3578 - val_accuracy: 0.8516\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8783 - val_loss: 0.3564 - val_accuracy: 0.8531\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8649 - val_loss: 0.3578 - val_accuracy: 0.8516\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8706 - val_loss: 0.3562 - val_accuracy: 0.8516\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8684 - val_loss: 0.3560 - val_accuracy: 0.8531\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8611 - val_loss: 0.3575 - val_accuracy: 0.8512\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8713 - val_loss: 0.3606 - val_accuracy: 0.8466\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8756 - val_loss: 0.3559 - val_accuracy: 0.8538\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8795 - val_loss: 0.3575 - val_accuracy: 0.8527\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8779 - val_loss: 0.3575 - val_accuracy: 0.8531\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8743 - val_loss: 0.3567 - val_accuracy: 0.8489\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3056 - accuracy: 0.8861 - val_loss: 0.3570 - val_accuracy: 0.8519\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3038 - accuracy: 0.8783 - val_loss: 0.3574 - val_accuracy: 0.8512\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8682 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8772 - val_loss: 0.3583 - val_accuracy: 0.8504\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8702 - val_loss: 0.3567 - val_accuracy: 0.8538\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8728 - val_loss: 0.3571 - val_accuracy: 0.8501\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8685 - val_loss: 0.3562 - val_accuracy: 0.8523\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3163 - accuracy: 0.8732 - val_loss: 0.3573 - val_accuracy: 0.8485\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3150 - accuracy: 0.8671 - val_loss: 0.3566 - val_accuracy: 0.8523\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8655 - val_loss: 0.3577 - val_accuracy: 0.8538\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8658 - val_loss: 0.3586 - val_accuracy: 0.8470\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8780 - val_loss: 0.3556 - val_accuracy: 0.8504\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8718 - val_loss: 0.3577 - val_accuracy: 0.8527\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8742 - val_loss: 0.3557 - val_accuracy: 0.8512\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8711 - val_loss: 0.3577 - val_accuracy: 0.8485\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8813 - val_loss: 0.3572 - val_accuracy: 0.8550\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8725 - val_loss: 0.3574 - val_accuracy: 0.8519\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3200 - accuracy: 0.8721 - val_loss: 0.3572 - val_accuracy: 0.8554\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3134 - accuracy: 0.8716 - val_loss: 0.3572 - val_accuracy: 0.8516\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8607 - val_loss: 0.3584 - val_accuracy: 0.8489\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8790 - val_loss: 0.3574 - val_accuracy: 0.8474\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8733 - val_loss: 0.3568 - val_accuracy: 0.8527\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8712 - val_loss: 0.3565 - val_accuracy: 0.8493\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8727 - val_loss: 0.3572 - val_accuracy: 0.8478\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8728 - val_loss: 0.3587 - val_accuracy: 0.8497\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3391 - accuracy: 0.8614 - val_loss: 0.3606 - val_accuracy: 0.8474\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8643 - val_loss: 0.3582 - val_accuracy: 0.8508\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8636 - val_loss: 0.3597 - val_accuracy: 0.8478\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3146 - accuracy: 0.8764 - val_loss: 0.3579 - val_accuracy: 0.8519\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3173 - accuracy: 0.8726 - val_loss: 0.3578 - val_accuracy: 0.8485\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8719 - val_loss: 0.3575 - val_accuracy: 0.8489\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8685 - val_loss: 0.3577 - val_accuracy: 0.8482\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.8780 - val_loss: 0.3590 - val_accuracy: 0.8482\n",
            "<keras.callbacks.History object at 0x7f1e7ea5fb50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3cY6hDz-yxw",
        "outputId": "d5d1abc7-dc01-40ea-a18e-a427660f236b"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred> 0.5)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "score = accuracy_score(y_pred,y_test)\n",
        "print('Le taux de précision est de : {}%'.format(score*100))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [ True]\n",
            " [False]\n",
            " [False]]\n",
            "[[1526   81]\n",
            " [ 190  203]]\n",
            "Le taux de précision est de : 86.45%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}